{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2-B5UZxUchfd"
   },
   "source": [
    "# Análisis de MNIST con tf.keras, tf.data y eager execution\n",
    "\n",
    "**Profesor:** Roberto Muñoz <br />\n",
    "**E-mail:** <rmunoz@metricarts.com> <br />\n",
    "\n",
    "**Colaborador:** Sebastián Arpón <br />\n",
    "**E-mail:** <rmunoz@metricarts.com> <br />\n",
    "\n",
    "En este laboratorio crearemos una red neuronal que pueda detectar a que digito corresponde una imagen que recibe (note que cada imagen contendra solo un digito). Utilizaremos la API `tf.data` [Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) la cual es muy eficiente e incluye funcionalidades como el shuffling y batching. \n",
    "\n",
    "El conjunto de datos con el que trabajaremos es el MINST el cual, como veremos mas adelante esta incluido en KERAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "902Rjd5DZroO"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Activando Eager\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "evWlYUkYefG8"
   },
   "outputs": [],
   "source": [
    "# obteniendo la data\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisamos el tamaño de train_images y train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_images))\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_labels))\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisamos un par de imágenes del dataset train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=np.random.randint(len(train_images))\n",
    "\n",
    "print(\"Indice del registro: \", i)\n",
    "print(\"Label: \", train_labels[i])\n",
    "plt.imshow(train_images[i,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformamos train_images y test_images de 28x28 a 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JA3braIeeggc"
   },
   "outputs": [],
   "source": [
    "# Chequeando el tamaño de los conjuntos de entrenamiento y test\n",
    "TRAINING_SIZE = len(train_images)\n",
    "TEST_SIZE = len(test_images)\n",
    "\n",
    "# transformando desde (N, 28, 28) a (N, 784)\n",
    "train_images = np.reshape(train_images, (TRAINING_SIZE, 784))\n",
    "test_images = np.reshape(test_images, (TEST_SIZE, 784))\n",
    "\n",
    "# Transformando cada arreglo desde uint8 a float32\n",
    "train_images = train_images.astype(np.float32)\n",
    "test_images = test_images.astype(np.float32)\n",
    "train_labels = train_labels.astype(np.float32)\n",
    "test_labels = test_labels.astype(np.float32)\n",
    "\n",
    "# Convirtiendo cada valor desde [0,255] a [0,1] \n",
    "train_images /= 255\n",
    "test_images /=  255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "wbwRqi0BeicT"
   },
   "outputs": [],
   "source": [
    "NUM_DIGITS = 10\n",
    "\n",
    "print(\"Previo al cambio de formato\", train_labels[0]) # The format of the labels before conversion\n",
    "\n",
    "train_labels  = tf.keras.utils.to_categorical(train_labels, NUM_DIGITS)\n",
    "\n",
    "print(\"Posterior al cambio de formato\", train_labels[0]) # The format of the labels after conversion\n",
    "\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, NUM_DIGITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jjNr3gr3ejh2"
   },
   "outputs": [],
   "source": [
    "# Creando la red neuronal con KERAS\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(784,)))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "\n",
    "# Creando el optimizador \n",
    "# Esto es obligatorio mientras usamos eager execution\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001)\n",
    "\n",
    "# Ahora compilaremos y mostraremos el resultado de nuestro modelo\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zUZPvDQYe5Xu"
   },
   "source": [
    "### Step 1) Creando un tf.data Dataset\n",
    "\n",
    "Ahora usaremos `tf.data.Dataset` [API](https://www.tensorflow.org/api_docs/python/tf/data) para convertir los arreglos de Numpy en un dataset de TensorFlow\n",
    "\n",
    "A continuacion crearemos un ciclo **for** que servira como una introduccion en la creacion de ciclos de entrenamientos personalizados. Aunque esencialmente estos ciclos hacer lo mismo que `model.fit`, esto nos permite personalizar todo el proceso y recolectar distintas metricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "sdBd2pd_fdue"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=128\n",
    "\n",
    "# Dado que tf.data puede funcionar en colecciones de datos potencialmente grandes\n",
    "# La desordenaremos por partes.\n",
    "SHUFFLE_SIZE = 10000 \n",
    "\n",
    "# Creando el dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "dataset = dataset.shuffle(SHUFFLE_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ksAR-C6xgUu4"
   },
   "source": [
    "### Step 2) Iterando sobre el dataset\n",
    "Aca entrenaremos sobre el dataset usando los distintos batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "kNgnUKPvgSCz"
   },
   "outputs": [],
   "source": [
    "EPOCHS=5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for images, labels in dataset:\n",
    "        print(type(images), type(labels))\n",
    "        train_loss, train_accuracy = model.train_on_batch(images, labels)\n",
    "  \n",
    "  # Obtenemos cualquier metrica o ajustamos los parametros de entrenamiento\n",
    "    print('Epoch #%d\\t Loss: %.6f\\tAccuracy: %.6f' % (epoch + 1, train_loss, train_accuracy))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "tg5U3Iqkgo3J"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy: %.2f' % (accuracy))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "2-mnist-with-keras-eager-and-tf-data.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
